{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cc948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 19:58:17.106873: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 19:58:18.034774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066dc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1ab9e4-b9f2-4452-8771-875dd43f3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [{'name':'knife', 'id':1}, {'name':'pen', 'id':2}, {'name':'gun', 'id':3}]\n",
    "\n",
    "# with open(files['LABELMAP'], 'w') as f:\n",
    "#     for label in labels:\n",
    "#         f.write('item { \\n')\n",
    "#         f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "#         f.write('\\tid:{}\\n'.format(label['id']))\n",
    "#         f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cf40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff947aa6-fb55-4cef-9363-b426616db95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending sms\n",
    "from twilio.rest impoer client\n",
    "account_sid='AC6cdaab22381550c272197eadea6d028b'\n",
    "auth_token='f8316367bc34d19bd86c3344a6452721'\n",
    "\n",
    "twilio_number='+15188737096'\n",
    "target_number='+918368227176'\n",
    "def sms(north,east,lst,long):\n",
    "    client=Client(account_sid,auth_token)\n",
    "    message=client.message.create(\n",
    "        body=(f\"location:\\nNorth={north},East={east},latitude:{lst},Decimal Longitude :{long}\")\n",
    "        from_=keys.twilio_number,\n",
    "        to=target_number\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3b5761-a30e-4261-87b6-6572512128fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCATION FUNCTION\n",
    "import PIL.Image\n",
    "import PIL.ExifTags\n",
    "\n",
    "def location(img):\n",
    "    exif = {\n",
    "        PIL.ExifTags.TAGS[k]: v\n",
    "        for k, v in img._getexif().items() \n",
    "        if k in PIL.ExifTags.TAGS\n",
    "    }\n",
    "    \n",
    "    if 'GPSInfo' not in exif:\n",
    "        raise ValueError(\"No GPS information found in the image's EXIF data.\")\n",
    "    \n",
    "    gps_info = exif['GPSInfo']\n",
    "    \n",
    "    north = gps_info[2]\n",
    "    east = gps_info[4]\n",
    "    \n",
    "    lst = float(((((north[0] * 60) + north[1]) * 60) + north[2]) / 3600)  \n",
    "    long = float(((((east[0] * 60) + east[1]) * 60) + east[2]) / 3600) \n",
    "    sms(north,east,lst,long)\n",
    "    \n",
    "    return north, east, lst, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5e2b47-7ae3-4ae2-930d-112f17334b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('image'):\n",
    "    os.makedirs('image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe14689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 19:58:19.577218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2023-08-10 19:58:19.577244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: shubham-IdeaPad-Gaming-3-15IMH05\n",
      "2023-08-10 19:58:19.577249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: shubham-IdeaPad-Gaming-3-15IMH05\n",
      "2023-08-10 19:58:19.577317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 520.61.5\n",
      "2023-08-10 19:58:19.577332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  525.125.06  Release Build  (dvs-builder@U16-A23-14-1)  Tue May 30 05:12:48 UTC 2023\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "# Load pipeline config and build a detection model\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-47')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07d7e04-6640-4937-859d-599f27898c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad8bc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@88.141] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "capture_interval = 4 * 60  # 4 minutes in seconds\n",
    "capture_last_time = time.time()  # Initialize the last capture time\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.4,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    if np.any(detections['detection_scores'] > 0.8) and (current_time - capture_last_time)>= capture_interval:\n",
    "        image_filename = f\"images/detected_image_{current_time}.jpg\"\n",
    "        cv2.imwrite(image_filename, image_np)\n",
    "        capture_last_time = current_time\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4bea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Tensorflow_probability==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0720f-929e-4518-8980-00dbcea31277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c63e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-06 00:05:28.143409: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-06 00:05:28.817111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "TensorFlow 2.0 Upgrade Script\n",
      "-----------------------------\n",
      "Converted 0 files\n",
      "Detected 0 issues that require attention\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Make sure to read the detailed log 'log.txt'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tf_upgrade_v2 --intree code_1.x/ --outtree code_2.x/ --reportfile log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e9fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.19.0\n",
      "  Downloading protobuf-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.49.0 requires protobuf<4.24.0,>=3.20.3, but you have protobuf 3.19.0 which is incompatible.\n",
      "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
      "googleapis-common-protos 1.60.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
      "tensorboard 2.13.0 requires protobuf>=3.19.6, but you have protobuf 3.19.0 which is incompatible.\n",
      "tensorflow 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.0 which is incompatible.\n",
      "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.0 which is incompatible.\n",
      "tensorflow-hub 0.14.0 requires protobuf>=3.19.6, but you have protobuf 3.19.0 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33c17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /home/shubham/anaconda3/envs/surveillance/lib/python3.8/site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/shubham/anaconda3/envs/surveillance/lib/python3.8/site-packages (from opencv-python-headless) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69db297c-827a-480e-8241-17c36d1db803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/shubham/anaconda3/envs/surveillance/lib/python3.8/site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/shubham/anaconda3/envs/surveillance/lib/python3.8/site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a91c64-6ce8-41c9-b5a4-1540b70e52f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.061] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25c8ac-faba-47e0-85f5-4a3d3fad07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def main():\n",
    "    # Open the default camera (index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Camera Feed', frame)\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surveillance",
   "language": "python",
   "name": "surveillance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
